{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c468709d",
   "metadata": {},
   "source": [
    "# ANLI Baseline\n",
    "\n",
    "This model illustrates how to use the DeBERTa-v3-base-mnli-fever-anli model to perform specialized inference on the ANLI dataset.\n",
    "This dataset has 184M parameters. It was trained in 2021 on the basis of a BERT-like embedding approach: \n",
    "* The premise and the hypothesis are encoded using the DeBERTa-v3-base contextual encoder\n",
    "* The encodings are then compared on a fine-tuned model to predict a distribution over the classification labels (entailment, contradiction, neutral)\n",
    "\n",
    "Reported accuracy on ANLI is 0.495 (see https://huggingface.co/MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cec0d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002c2ed0fcde41cea3d9cd2c5a780397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2036768556224cb9a53fc4dbd3be81d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ee67d64a7345bf8d540ad52b064483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f50e74d3244c968c5a3647d2e7c670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a396549970f4ed1ac05e1d5b7397df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa83ed53f2945738cde10075abace2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6288094730e4046987422e892237dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/369M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a47aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entailment': 6.6, 'neutral': 17.3, 'contradiction': 76.1}\n"
     ]
    }
   ],
   "source": [
    "premise = \"I first thought that I liked the movie, but upon second thought it was actually disappointing.\"\n",
    "hypothesis = \"The movie was good.\"\n",
    "\n",
    "input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "output = model(input[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cfe31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_NLI(premise, hypothesis):\n",
    "    input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "    output = model(input[\"input_ids\"].to(device))\n",
    "    prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "    prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2954d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entailment': 0.1, 'neutral': 99.8, 'contradiction': 0.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_with_NLI(\"The weather is nice today.\", \"It is sunny outside.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "923ea5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(pred_dict):\n",
    "    if pred_dict[\"entailment\"] > pred_dict[\"contradiction\"]  and pred_dict[\"entailment\"] > pred_dict[\"neutral\"]:\n",
    "        return \"entailment\"\n",
    "    elif pred_dict[\"contradiction\"] > pred_dict[\"entailment\"]  and pred_dict[\"contradiction\"] > pred_dict[\"neutral\"]:\n",
    "        return \"contradiction\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af257dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(evaluate_with_NLI(\"The weather is nice today.\", \"It is sunny outside.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "929632f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entailment'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(evaluate_with_NLI(\"It is sunny outside.\", \"The weather is nice today.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "747c0cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contradiction'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(evaluate_with_NLI(\"It is sunny outside.\", \"The weather is terrible today.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab422d",
   "metadata": {},
   "source": [
    "## Load ANLI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0438789b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccafb8d2a5a41868a0d89b8659ec57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8959fee256754ce6af7c421f5a9dd8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train_r1-00000-of-00001.parqu(…):   0%|          | 0.00/3.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad14104af5b64e7382e81a07161a3597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/dev_r1-00000-of-00001.parquet:   0%|          | 0.00/351k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12516d0289274d949d25ef71ec96b30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/test_r1-00000-of-00001.parque(…):   0%|          | 0.00/353k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7108a4b101de490bb5cc791ec979d71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train_r2-00000-of-00001.parqu(…):   0%|          | 0.00/6.53M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44285bf509b84f6e809e788bbec6f36d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/dev_r2-00000-of-00001.parquet:   0%|          | 0.00/351k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d79d4a4716c49c595c54df38950e4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/test_r2-00000-of-00001.parque(…):   0%|          | 0.00/362k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8fa98ae47043a3a64a4671dda618f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train_r3-00000-of-00001.parqu(…):   0%|          | 0.00/14.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f41d4fa35048019a29b5359a5cd36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/dev_r3-00000-of-00001.parquet:   0%|          | 0.00/434k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c37f636a04b460589e1ef105a620c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/test_r3-00000-of-00001.parque(…):   0%|          | 0.00/435k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508c4d521b0e4e83bd065b1943cda735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_r1 split:   0%|          | 0/16946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d3194445b64c5d9a2b6228bd30f423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev_r1 split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fd3c4926014b8a91565e30c2d50ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_r1 split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db214415b814e6d8c5309e1b993d9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_r2 split:   0%|          | 0/45460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d2331c1fdf453fb4dccc7b9c02d0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev_r2 split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4b8b5b1fec40f08b876016a0206952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_r2 split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b4bf1f19604250835ab6d143757799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_r3 split:   0%|          | 0/100459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677c3fc873024eb99d6600741b4e7dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev_r3 split:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e5863b825a4671a4dd852c16ca3537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_r3 split:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7e11885a9f44f9b9171b4b8cf39d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428717f1c0344c63a5cf6e79c133e62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef5170e32ff44ff9b197be233b19693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86827fb31f141e3b9534582ac0f354c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/45460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3569847b8d4b1eafd9091b60c4dff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c68081e72d4616af63cb9b737f7726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6ebafbcd4349a2a9917182e14f7ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8872fc002d234421aa06b3cd3b555bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077a61953a864fbda06e79035c9589c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"facebook/anli\")\n",
    "dataset = dataset.filter(lambda x: x['reason'] != None and x['reason'] != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e59927ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train_r1: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 2923\n",
       "    })\n",
       "    dev_r1: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test_r1: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    train_r2: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 4861\n",
       "    })\n",
       "    dev_r2: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test_r2: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    train_r3: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 13375\n",
       "    })\n",
       "    dev_r3: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "    test_r3: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8262068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the ANLI dataset\n",
    "from tqdm import tqdm\n",
    "def evaluate_on_dataset(dataset):\n",
    "    results = []\n",
    "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    for example in tqdm(dataset):\n",
    "        premise = example['premise']\n",
    "        hypothesis = example['hypothesis']\n",
    "        prediction = evaluate_with_NLI(premise, hypothesis)\n",
    "        results.append({\n",
    "            'premise': premise,\n",
    "            'hypothesis': hypothesis,\n",
    "            'prediction': prediction,\n",
    "            'pred_label': get_prediction(prediction),\n",
    "            'gold_label': label_names[example['label']],\n",
    "            'reason': example['reason']\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f858feae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [06:16<00:00,  3.19it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_test_r3 = evaluate_on_dataset(dataset['test_r3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8efb717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'premise': \"It is Sunday today, let's take a look at the most popular posts of the last couple of days. Most of the articles this week deal with the iPhone, its future version called the iPhone 8 or iPhone Edition, and new builds of iOS and macOS. There are also some posts that deal with the iPhone rival called the Galaxy S8 and some other interesting stories. The list of the most interesting articles is available below. Stay tuned for more rumors and don't forget to follow us on Twitter.\",\n",
       "  'hypothesis': 'The day of the passage is usually when Christians praise the lord together',\n",
       "  'prediction': {'entailment': 2.4, 'neutral': 97.4, 'contradiction': 0.2},\n",
       "  'pred_label': 'neutral',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': \"Sunday is considered Lord's Day\"},\n",
       " {'premise': 'By The Associated Press WELLINGTON, New Zealand (AP) — All passengers and crew have survived a crash-landing of a plane in a lagoon in the Federated States of Micronesia. WELLINGTON, New Zealand (AP) — All passengers and crew have survived a crash-landing of a plane in a lagoon in the Federated States of Micronesia. Copyright © 2018 The Associated Press. All rights reserved. This material may not be published, broadcast, written or redistributed.',\n",
       "  'hypothesis': 'No children were killed in the accident.',\n",
       "  'prediction': {'entailment': 0.1, 'neutral': 99.9, 'contradiction': 0.0},\n",
       "  'pred_label': 'neutral',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': 'The context confirms that everybody survived the accident, so there is no way that a child was killed.'},\n",
       " {'premise': 'Tokyo - Food group Nestle is seeking to lure Japanese holiday shoppers with a taste for fine snacking with a gold-wrapped Kit Kat chocolate bar. The single finger Kit Kat is wrapped in a thin layer of gold leaf. Only 500 of the bars go on sale from Dec. 29 with a price tag of around 2,016 yen ($16). The Kit Kat chocolate bar made its debut in Japan in 1973 and since then a variety of flavors -- from green tea to wasabi -- have been produced.',\n",
       "  'hypothesis': 'Japanese like kit kat. ',\n",
       "  'prediction': {'entailment': 84.0, 'neutral': 15.9, 'contradiction': 0.1},\n",
       "  'pred_label': 'entailment',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': 'according to the text, The Kit Kat chocolate bar made its debut in Japan in 1973 and since then a variety of flavors -- from green tea to wasabi -- have been produced, which means if  they have been so many produced it is because they like it. '},\n",
       " {'premise': 'Governor Greg Abbott has called for a statewide show of support for law enforcement Friday, July 7. Locally, a 15-minute program is planned at 9 a.m. at Memorial Lane Park, 550 N. Travis St. The governor is asking law enforcement officers to turn on red and blue flashing lights for one-minute at 10 a.m. Multiple law enforcement officers were shot and killed in Dallas one year ago.',\n",
       "  'hypothesis': 'Law enforcement officers and the people at the Travis St. memorial do not show their support at the same time.',\n",
       "  'prediction': {'entailment': 11.9, 'neutral': 75.8, 'contradiction': 12.3},\n",
       "  'pred_label': 'neutral',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': 'The Travis St.memorial program begins at 9 a.m. Law enforcement officers were asked to turn on red and blue flashing lights for one-minute at 10 a.m.'},\n",
       " {'premise': 'Sept 4 (Reuters) - J.P. Morgan Asset Management, a unit of JPMorgan Chase & Co, said it appointed Pietro Grassano the new country head for France. Based in Paris, Grassano started in his new role on Sept. 1, J.P. Morgan Asset Management said in a statement. Grassano, who has been with the company since 2002, was previously the head of sales for Italy, covering wholesale and retail distribution. He has earlier worked at BNP Paribas Asset Management.',\n",
       "  'hypothesis': 'Pietro Grassano was once the country head for France.',\n",
       "  'prediction': {'entailment': 2.9, 'neutral': 55.1, 'contradiction': 42.0},\n",
       "  'pred_label': 'neutral',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': '\"J.P. Morgan Asset Management, a unit of JPMorgan Chase & Co, said it appointed Pietro Grassano the new country head for France.\" I think it was difficult because I worded it past tense, \"He was ONCE the country head\", but I believe that statement is true because it is past Sept 1 when he was appointed.'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_r3[:5]  # Display the first 5 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e1258",
   "metadata": {},
   "source": [
    "## Evaluate Metrics\n",
    "\n",
    "Let's use the huggingface `evaluate` package to compute the performance of the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e2e9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "accuracy = load(\"accuracy\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "f1 = load(\"f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ab24e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d04f0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6666666666666666,\n",
       " 'f1': 0.6666666666666666,\n",
       " 'precision': 1.0,\n",
       " 'recall': 0.5}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_metrics.compute(predictions=[0, 1, 0], references=[0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909d58b",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "Compute the classification metrics on the baseline model on each section of the ANLI dataset.\n",
    "\n",
    "https://www.kaggle.com/code/faijanahamadkhan/llm-evaluation-framework-hugging-face provides good documentation on how to use the Huggingface evaluate library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51fbc81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1e6e27f",
   "metadata": {},
   "source": [
    "1.1\n",
    "\n",
    "Implement the part of the evaluation on the ANLI samples that have a non-empty 'reason' field on the 'test'\n",
    "parts of the dataset (there are three such sections test_r1, test_r2 and test_r3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a44f134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:46<00:00,  2.89it/s]\n",
      "100%|██████████| 1000/1000 [05:32<00:00,  3.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'premise': 'There is a little Shia community in El Salvador. There is an Islamic Library operated by the Shia community, named \"Fatimah Az-Zahra\". They published the first Islamic magazine in Central America: \"Revista Biblioteca Islámica\". Additionally, they are credited with providing the first and only Islamic library dedicated to spreading Islamic culture in the country.',\n",
       "  'hypothesis': 'The community is south of the United States.',\n",
       "  'prediction': {'entailment': 94.5, 'neutral': 1.7, 'contradiction': 3.8},\n",
       "  'pred_label': 'entailment',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': 'The community is in El Salvador which is south of the US.'},\n",
       " {'premise': '\"Look at Me (When I Rock Wichoo)\" is a song by American indie rock band Black Kids, taken from their debut album \"Partie Traumatic\". It was released in the UK by Almost Gold Recordings on September 8, 2008 and debuted on the Top 200 UK Singles Chart at number 175.',\n",
       "  'hypothesis': 'The song was released in America in September 2008',\n",
       "  'prediction': {'entailment': 3.1, 'neutral': 7.5, 'contradiction': 89.5},\n",
       "  'pred_label': 'contradiction',\n",
       "  'gold_label': 'neutral',\n",
       "  'reason': \"It doesn't state if it was released anywhere outside of the UK\"},\n",
       " {'premise': '\"Eternally\" is a song with music by Charles Chaplin, and words by the English lyricists Geoff Parsons and John Turner. The music was initially composed for Charles Chaplin\\'s film \"Limelight\" (1952) titled \"Terry\\'s Theme\"; the film won an Oscar for \"Best Original Dramatic Score\" at the',\n",
       "  'hypothesis': 'The words to Eternally were written partially by Geoff Parsons',\n",
       "  'prediction': {'entailment': 99.7, 'neutral': 0.2, 'contradiction': 0.1},\n",
       "  'pred_label': 'entailment',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': 'This is correct because it says him and another wrote the words. I think the system misunderstood the word partially'},\n",
       " {'premise': 'Louis S. Peterson (June 17, 1922 – April 27, 1998) was a playwright, actor, screenwriter, and professor. He was an American playwright and the first African-American playwright to have a dramatic play produced on Broadway. He was also one of the first African-American writers to be nominated for an Emmy Award.',\n",
       "  'hypothesis': 'Louis S. Peterson was an adult when he wrote his first play.',\n",
       "  'prediction': {'entailment': 0.9, 'neutral': 98.5, 'contradiction': 0.6},\n",
       "  'pred_label': 'neutral',\n",
       "  'gold_label': 'neutral',\n",
       "  'reason': 'The article does not state his age. Unsure why the system doesnt know this , maybe the word adult.'},\n",
       " {'premise': 'Things Happen at Night is a 1947 British supernatural ghost comedy film directed by Francis Searle and starring Gordon Harker, Alfred Drayton, Robertson Hare and Gwynneth Vaughan. The film is based upon a stage play, \"The Poltergeist\", by Frank Harvey Jnr.',\n",
       "  'hypothesis': 'Frank Harvey Jnr. wrote Things Happen at Night .',\n",
       "  'prediction': {'entailment': 12.5, 'neutral': 15.4, 'contradiction': 72.1},\n",
       "  'pred_label': 'contradiction',\n",
       "  'gold_label': 'contradiction',\n",
       "  'reason': 'It is based off of the play, but he did not actually write it. The system is unable to figure out one way or another.'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_r1 = evaluate_on_dataset(dataset['test_r1'])\n",
    "pred_test_r2 = evaluate_on_dataset(dataset['test_r2'])\n",
    "\n",
    "pred_test_r1[:5] \n",
    "pred_test_r2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63f0a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"contradiction\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52108229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_evaluation_metrics(test_predictions, test_references):\n",
    "    print(\"Accuracy for test dataset\")\n",
    "    print(accuracy.compute(predictions=test_predictions, references=test_references))\n",
    "\n",
    "    print(\"Precision micro for test dataset\")\n",
    "    print(precision.compute(predictions=test_predictions, references=test_references, average = \"micro\"))\n",
    "\n",
    "    print(\"Recall micro for test dataset\")\n",
    "    print(recall.compute(predictions=test_predictions, references=test_references, average = \"micro\"))\n",
    "\n",
    "    print(\"F1 micro for test dataset\")\n",
    "    print(f1.compute(predictions=test_predictions, references=test_references, average = \"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b13c878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test dataset\n",
      "{'accuracy': 0.712}\n",
      "Precision micro for test dataset\n",
      "{'precision': 0.712}\n",
      "Recall micro for test dataset\n",
      "{'recall': 0.712}\n",
      "F1 micro for test dataset\n",
      "{'f1': 0.712}\n"
     ]
    }
   ],
   "source": [
    "test_r1_predictions = [label_map[e[\"pred_label\"]] for e in pred_test_r1]\n",
    "test_r1_gold = [label_map[e[\"gold_label\"]] for e in pred_test_r1]\n",
    "\n",
    "display_evaluation_metrics(test_r1_predictions, test_r1_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8fb9ee06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test dataset\n",
      "{'accuracy': 0.547}\n",
      "Precision micro for test dataset\n",
      "{'precision': 0.547}\n",
      "Recall micro for test dataset\n",
      "{'recall': 0.547}\n",
      "F1 micro for test dataset\n",
      "{'f1': 0.547}\n"
     ]
    }
   ],
   "source": [
    "test_r2_predictions = [label_map[e[\"pred_label\"]] for e in pred_test_r2]\n",
    "test_r2_gold = [label_map[e[\"gold_label\"]] for e in pred_test_r2]\n",
    "\n",
    "display_evaluation_metrics(test_r2_predictions, test_r2_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45cfa45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test dataset\n",
      "{'accuracy': 0.495}\n",
      "Precision micro for test dataset\n",
      "{'precision': 0.495}\n",
      "Recall micro for test dataset\n",
      "{'recall': 0.495}\n",
      "F1 micro for test dataset\n",
      "{'f1': 0.495}\n"
     ]
    }
   ],
   "source": [
    "test_r3_predictions = [label_map[e[\"pred_label\"]] for e in pred_test_r3]\n",
    "test_r3_gold = [label_map[e[\"gold_label\"]] for e in pred_test_r3]\n",
    "\n",
    "display_evaluation_metrics(test_r3_predictions, test_r3_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ccc06f",
   "metadata": {},
   "source": [
    "1.2\n",
    "\n",
    "Investigate Errors of the NLI Model.\n",
    "\n",
    "Sample 20 errors from the baseline model, and investigate the reasons the model made a mistake.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15685546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': \"Shadowboxer is a 2005 crime thriller film directed by Lee Daniels and starring Academy Award winners Cuba Gooding Jr., Helen Mirren, and Mo'Nique. It opened in limited release in six cities: New York, Los Angeles, Washington, D.C., Baltimore, Philadelphia, and Richmond, Virginia.\", 'hypothesis': \"Shadowboxer was written and directed by Lee Daniels and was starring Academy Award winners Cuba Gooding Jr., Helen Mirren, and Mo'Nique.\", 'prediction': {'entailment': 53.2, 'neutral': 46.1, 'contradiction': 0.8}, 'pred_label': 'entailment', 'gold_label': 'neutral', 'reason': 'It is not know who wrote the Shadowboxer. The system can get confused if a small detail is added for a person while many correct details are written.'}\n",
      "{'premise': \"Edmond (or Edmund) Halley, FRS (pronounced ; 8 November [O.S. 29 October] 1656 – 25 January 1742 [O.S. 14 January 1741] ) was an English astronomer, geophysicist, mathematician, meteorologist, and physicist who is best known for computing the orbit of Halley's Comet. He was the second Astronomer Royal in Britain, succeeding John Flamsteed.\", 'hypothesis': 'Edmond Halley was born outside of the United Kingdom. ', 'prediction': {'entailment': 0.2, 'neutral': 0.7, 'contradiction': 99.1}, 'pred_label': 'contradiction', 'gold_label': 'neutral', 'reason': 'We know Edmond Halley is English, but we are not sure if he was actually born in the United Kingdom or not. '}\n",
      "{'premise': 'Dyllan McGee is a documentary filmmaker and founder of McGee Media. In partnership with Peter Kunhardt, McGee produced \"Gloria: In Her Own Words” (HBO), “Finding Your Roots with Henry Louis Gates, Jr.” (PBS), \"MAKERS: Women Who Make America” and many more. McGee is the Founder and Executive Producer of AOL’s MAKERS.', 'hypothesis': 'D McGee is a filmmaker who founded their own company. They made many films, that were broadcast on many US networks. ', 'prediction': {'entailment': 6.3, 'neutral': 93.3, 'contradiction': 0.4}, 'pred_label': 'neutral', 'gold_label': 'entailment', 'reason': 'The AI cannot know where the films were broadcast. '}\n",
      "{'premise': 'Oksa is a village in Jędrzejów County, Świętokrzyskie Voivodeship, in south-central Poland. It is the seat of the gmina (administrative district) called Gmina Oksa. It lies approximately 18 km north-west of Jędrzejów and 41 km south-west of the regional capital Kielce. The village has an approximate population of 890.', 'hypothesis': 'The population of Oksa is large', 'prediction': {'entailment': 0.7, 'neutral': 98.0, 'contradiction': 1.3}, 'pred_label': 'neutral', 'gold_label': 'contradiction', 'reason': 'Oksa is a small village with a population of 890, which is not large. The system does not understand relative size. '}\n",
      "{'premise': \"The 2009–10 Tour de Ski was the 4th edition of the Tour de Ski and took place 1–10 January 2010. The race started in Oberhof, Germany, and ended in Val di Fiemme, Italy. The defending champions are Switzerland's Dario Cologna for the men and Finland's Virpi Kuitunen. This year's event was won by Lukáš Bauer of the Czech Republic for the men and Poland's Justyna Kowalczyk for the women.\", 'hypothesis': 'Dario Cologna won the 3rd edition of the Tour de Ski.', 'prediction': {'entailment': 2.1, 'neutral': 97.7, 'contradiction': 0.1}, 'pred_label': 'neutral', 'gold_label': 'entailment', 'reason': 'It said he was a defending champion which means he won the year before, making that the 3rd iteration of the race.'}\n",
      "{'premise': 'Aram is a 2002 French action film. It takes place in France between 1993 and 2001, wherein French-Armenian fighters supply arms to Nagorno-Karabakh and kill a visiting Turkish general. The film was released in 2002 in theatres in France, and made its American debut in 2004 at the Armenian Film Festival in San Francisco.', 'hypothesis': 'In 2002, the Armenian Film Festival was held in San Francisco.', 'prediction': {'entailment': 6.2, 'neutral': 1.5, 'contradiction': 92.3}, 'pred_label': 'contradiction', 'gold_label': 'neutral', 'reason': \"We don't know where or if there was even a 2002 Armenian film festival.\"}\n",
      "{'premise': 'The diocese of Vannida (in Latin: Dioecesis Vannidensis) is a suppressed and titular See of the Roman Catholic Church. It was centered on the ancient Roman Town of Vannida, in what is today Algeria, is an ancient episcopal seat of the Roman province of Mauritania Cesariense.', 'hypothesis': 'The diocese of Vannida is located in Europe', 'prediction': {'entailment': 60.2, 'neutral': 6.9, 'contradiction': 32.9}, 'pred_label': 'entailment', 'gold_label': 'contradiction', 'reason': 'No it is in Algeria'}\n",
      "{'premise': '\"Look at Me (When I Rock Wichoo)\" is a song by American indie rock band Black Kids, taken from their debut album \"Partie Traumatic\". It was released in the UK by Almost Gold Recordings on September 8, 2008 and debuted on the Top 200 UK Singles Chart at number 175.', 'hypothesis': 'The song was released in America in September 2008', 'prediction': {'entailment': 3.1, 'neutral': 7.5, 'contradiction': 89.5}, 'pred_label': 'contradiction', 'gold_label': 'neutral', 'reason': \"It doesn't state if it was released anywhere outside of the UK\"}\n",
      "{'premise': 'Public Domain Day is an observance of when copyrights expire and works enter into the public domain. This legal transition of copyright works into the public domain usually happens every year on 1 January based on the individual copyright laws of each country.', 'hypothesis': 'Public Domain Day always happens on January 1st.', 'prediction': {'entailment': 83.5, 'neutral': 12.6, 'contradiction': 3.8}, 'pred_label': 'entailment', 'gold_label': 'contradiction', 'reason': \"I think the system was confused because Public Domain Day usually happens on January 1st, but it's not guaranteed to happen that specific day.\"}\n",
      "{'premise': '\"Beez in the Trap\" is a song by rapper Nicki Minaj for her second studio album, \"\" (2012). It was written by Minaj, Maurice Jordan, and 2 Chainz, who contributed a guest verse to the song, while production was handled by Kenoe. The track was released as the album\\'s third single on May 29, 2012 following \"Starships\" and \"Right by My Side\".', 'hypothesis': 'The song was released on the last day of May, 2012', 'prediction': {'entailment': 98.0, 'neutral': 0.9, 'contradiction': 1.1}, 'pred_label': 'entailment', 'gold_label': 'contradiction', 'reason': 'It was released on May 29, 2012'}\n",
      "{'premise': 'The Kilpatrick and Beatty text-messaging scandal was a political-sex scandal emerging from a whistle blower lawsuit involving former Detroit Police Chief Gary Brown, Detroit Mayor Kwame Kilpatrick and his former Chief of Staff and paramour Christine Beatty.', 'hypothesis': 'Kilpatrick was a police officer', 'prediction': {'entailment': 93.5, 'neutral': 3.5, 'contradiction': 3.0}, 'pred_label': 'entailment', 'gold_label': 'contradiction', 'reason': 'No Kilpatrick was the mayor'}\n",
      "{'premise': '\"Crawling\" is a song by American rock band Linkin Park. It is the second single from their debut album \"Hybrid Theory\" and is the fifth track on the album. It was released in 2001 as their second single and won a Grammy for Best Hard Rock Performance in 2002. In January 2011, \"Crawling\" was released in a Linkin Park DLC pack for \"Rock Band 3\".', 'hypothesis': '\"Crawling\" was written by Linkin Park for the DLC pack in \"Rock Band 3\".', 'prediction': {'entailment': 0.3, 'neutral': 97.8, 'contradiction': 1.9}, 'pred_label': 'neutral', 'gold_label': 'contradiction', 'reason': '\"Crawling\" was written for the album \"Hybrid Theory\", not for Rock Band where it featured 10 years later.'}\n",
      "{'premise': '\"Toi, la musique et moi\" (English translation: \"You, the Music and I\") was the Monegasque entry in the Eurovision Song Contest 1976, performed in French by French singer Mary Christy. Christy recorded the song in five languages; French, Italian (as \"La musica e noi due\"), Spanish (\"La música, tú y yo\"), German (\"Die Musik und ich\") and English (\"Thank You for Rushing into My Life\").', 'hypothesis': 'Christy performed a song in German for Eurovision 1976.', 'prediction': {'entailment': 53.2, 'neutral': 11.4, 'contradiction': 35.5}, 'pred_label': 'entailment', 'gold_label': 'contradiction', 'reason': 'The song in the Eurovision Song Contest 1976 was performed in French by French singer Mary Christy. Christy also recorded the song in German, which might have confused the algorithm.'}\n",
      "{'premise': 'Aloe ( or ), also written \"Aloë\", is a genus containing over 500 species of flowering succulent plants. The most widely known species is \"Aloe vera\", or \"true aloe\", so called because it is cultivated as the standard source of so-called \"aloe vera\" for assorted pharmaceutical purposes. Other species, such as \"Aloe ferox\", also are cultivated or harvested from the wild for similar applications.', 'hypothesis': 'Aloe is used mostly for the lips', 'prediction': {'entailment': 0.0, 'neutral': 6.2, 'contradiction': 93.8}, 'pred_label': 'contradiction', 'gold_label': 'neutral', 'reason': 'We do not know how aloe is used for primarily '}\n",
      "{'premise': \"It is Sunday today, let's take a look at the most popular posts of the last couple of days. Most of the articles this week deal with the iPhone, its future version called the iPhone 8 or iPhone Edition, and new builds of iOS and macOS. There are also some posts that deal with the iPhone rival called the Galaxy S8 and some other interesting stories. The list of the most interesting articles is available below. Stay tuned for more rumors and don't forget to follow us on Twitter.\", 'hypothesis': 'The day of the passage is usually when Christians praise the lord together', 'prediction': {'entailment': 2.4, 'neutral': 97.4, 'contradiction': 0.2}, 'pred_label': 'neutral', 'gold_label': 'entailment', 'reason': \"Sunday is considered Lord's Day\"}\n",
      "{'premise': 'By The Associated Press WELLINGTON, New Zealand (AP) — All passengers and crew have survived a crash-landing of a plane in a lagoon in the Federated States of Micronesia. WELLINGTON, New Zealand (AP) — All passengers and crew have survived a crash-landing of a plane in a lagoon in the Federated States of Micronesia. Copyright © 2018 The Associated Press. All rights reserved. This material may not be published, broadcast, written or redistributed.', 'hypothesis': 'No children were killed in the accident.', 'prediction': {'entailment': 0.1, 'neutral': 99.9, 'contradiction': 0.0}, 'pred_label': 'neutral', 'gold_label': 'entailment', 'reason': 'The context confirms that everybody survived the accident, so there is no way that a child was killed.'}\n",
      "{'premise': 'Governor Greg Abbott has called for a statewide show of support for law enforcement Friday, July 7. Locally, a 15-minute program is planned at 9 a.m. at Memorial Lane Park, 550 N. Travis St. The governor is asking law enforcement officers to turn on red and blue flashing lights for one-minute at 10 a.m. Multiple law enforcement officers were shot and killed in Dallas one year ago.', 'hypothesis': 'Law enforcement officers and the people at the Travis St. memorial do not show their support at the same time.', 'prediction': {'entailment': 11.9, 'neutral': 75.8, 'contradiction': 12.3}, 'pred_label': 'neutral', 'gold_label': 'entailment', 'reason': 'The Travis St.memorial program begins at 9 a.m. Law enforcement officers were asked to turn on red and blue flashing lights for one-minute at 10 a.m.'}\n",
      "{'premise': 'Sept 4 (Reuters) - J.P. Morgan Asset Management, a unit of JPMorgan Chase & Co, said it appointed Pietro Grassano the new country head for France. Based in Paris, Grassano started in his new role on Sept. 1, J.P. Morgan Asset Management said in a statement. Grassano, who has been with the company since 2002, was previously the head of sales for Italy, covering wholesale and retail distribution. He has earlier worked at BNP Paribas Asset Management.', 'hypothesis': 'Pietro Grassano was once the country head for France.', 'prediction': {'entailment': 2.9, 'neutral': 55.1, 'contradiction': 42.0}, 'pred_label': 'neutral', 'gold_label': 'entailment', 'reason': '\"J.P. Morgan Asset Management, a unit of JPMorgan Chase & Co, said it appointed Pietro Grassano the new country head for France.\" I think it was difficult because I worded it past tense, \"He was ONCE the country head\", but I believe that statement is true because it is past Sept 1 when he was appointed.'}\n",
      "{'premise': 'press release: Fresca Opera presents Opera Storytellers! Opera is a series of notes from the soul. Arias performed with the most intimate of instruments: The human voice. Accompanied by six strings and the history behind the notes, Opera Storytellers presents operatic music like you have never heard it before. Acoustic. Pure. Naked. Opera Storytellers performs this music the way it was intended to be. A connection without interference. Just pure music.', 'hypothesis': 'Fresca Opera is a unique type of music.', 'prediction': {'entailment': 15.2, 'neutral': 81.2, 'contradiction': 3.6}, 'pred_label': 'neutral', 'gold_label': 'entailment', 'reason': 'The scenario states that the music is \"like you have never heard it before,\" suggesting unique music.'}\n",
      "{'premise': 'The evacuation of Chinese workers in Libya highlights Beijing”s vulnerabilities as it partners with oil-rich regimes. Upheaval in Africa and the Middle East could force China to weigh political risks more carefully.The Chinese construction workers and their families huddled inside their company”s li Read the full story here: L.A. Times – Sparks', 'hypothesis': 'Chinese workers were forced to evacuate in Libya.', 'prediction': {'entailment': 3.2, 'neutral': 96.4, 'contradiction': 0.4}, 'pred_label': 'neutral', 'gold_label': 'entailment', 'reason': \"The workers had no choice but to evacuate from Libya due to the country's political turmoil.\"}\n"
     ]
    }
   ],
   "source": [
    "def sample_n_errors(pred_test, n):\n",
    "    samples = []\n",
    "    for test_result in pred_test:\n",
    "        if test_result['pred_label'] != test_result['gold_label']:\n",
    "            samples.append(test_result)\n",
    "            if len(samples) >= n:\n",
    "                break\n",
    "    return samples\n",
    "\n",
    "baseline_error_samples = sample_n_errors(pred_test_r1,7) + sample_n_errors(pred_test_r2,7) + sample_n_errors(pred_test_r3,6)\n",
    "\n",
    "for item in baseline_error_samples:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf5768",
   "metadata": {},
   "source": [
    "Common patterns behind errors:\n",
    "\n",
    "Failure to recognize missing or extra information → predicting entailment when it should be neutral.\n",
    "\n",
    "Lack of external knowledge → geography, word implications (e.g. “defending champion”).\n",
    "\n",
    "Overgeneralization or assumption-based reasoning.\n",
    "\n",
    "Misinterpretation of named roles or entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636efff1",
   "metadata": {},
   "source": [
    "Importing test_r3 results for 1.3 evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "728a2203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"pred_test_r3.json\", \"w\") as f:\n",
    "    json.dump(pred_test_r3, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
