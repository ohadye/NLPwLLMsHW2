{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c468709d",
   "metadata": {},
   "source": [
    "# ANLI Baseline\n",
    "\n",
    "This model illustrates how to use the DeBERTa-v3-base-mnli-fever-anli model to perform specialized inference on the ANLI dataset.\n",
    "This dataset has 184M parameters. It was trained in 2021 on the basis of a BERT-like embedding approach: \n",
    "* The premise and the hypothesis are encoded using the DeBERTa-v3-base contextual encoder\n",
    "* The encodings are then compared on a fine-tuned model to predict a distribution over the classification labels (entailment, contradiction, neutral)\n",
    "\n",
    "Reported accuracy on ANLI is 0.495 (see https://huggingface.co/MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cec0d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002c2ed0fcde41cea3d9cd2c5a780397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2036768556224cb9a53fc4dbd3be81d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ee67d64a7345bf8d540ad52b064483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f50e74d3244c968c5a3647d2e7c670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a396549970f4ed1ac05e1d5b7397df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa83ed53f2945738cde10075abace2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6288094730e4046987422e892237dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/369M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a47aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entailment': 6.6, 'neutral': 17.3, 'contradiction': 76.1}\n"
     ]
    }
   ],
   "source": [
    "premise = \"I first thought that I liked the movie, but upon second thought it was actually disappointing.\"\n",
    "hypothesis = \"The movie was good.\"\n",
    "\n",
    "input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "output = model(input[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cfe31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(premise, hypothesis):\n",
    "    input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "    output = model(input[\"input_ids\"].to(device))\n",
    "    prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "    prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2954d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entailment': 0.1, 'neutral': 99.8, 'contradiction': 0.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\"The weather is nice today.\", \"It is sunny outside.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923ea5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(pred_dict):\n",
    "    if pred_dict[\"entailment\"] > pred_dict[\"contradiction\"]  and pred_dict[\"entailment\"] > pred_dict[\"neutral\"]:\n",
    "        return \"entailment\"\n",
    "    elif pred_dict[\"contradiction\"] > pred_dict[\"entailment\"]:\n",
    "        return \"contradiction\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af257dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(evaluate(\"The weather is nice today.\", \"It is sunny outside.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "929632f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entailment'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(evaluate(\"It is sunny outside.\", \"The weather is nice today.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "747c0cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contradiction'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(evaluate(\"It is sunny outside.\", \"The weather is terrible today.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab422d",
   "metadata": {},
   "source": [
    "## Load ANLI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0438789b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccafb8d2a5a41868a0d89b8659ec57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8959fee256754ce6af7c421f5a9dd8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train_r1-00000-of-00001.parqu(…):   0%|          | 0.00/3.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad14104af5b64e7382e81a07161a3597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/dev_r1-00000-of-00001.parquet:   0%|          | 0.00/351k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12516d0289274d949d25ef71ec96b30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/test_r1-00000-of-00001.parque(…):   0%|          | 0.00/353k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7108a4b101de490bb5cc791ec979d71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train_r2-00000-of-00001.parqu(…):   0%|          | 0.00/6.53M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44285bf509b84f6e809e788bbec6f36d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/dev_r2-00000-of-00001.parquet:   0%|          | 0.00/351k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d79d4a4716c49c595c54df38950e4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/test_r2-00000-of-00001.parque(…):   0%|          | 0.00/362k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8fa98ae47043a3a64a4671dda618f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train_r3-00000-of-00001.parqu(…):   0%|          | 0.00/14.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f41d4fa35048019a29b5359a5cd36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/dev_r3-00000-of-00001.parquet:   0%|          | 0.00/434k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c37f636a04b460589e1ef105a620c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/test_r3-00000-of-00001.parque(…):   0%|          | 0.00/435k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508c4d521b0e4e83bd065b1943cda735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_r1 split:   0%|          | 0/16946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d3194445b64c5d9a2b6228bd30f423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev_r1 split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fd3c4926014b8a91565e30c2d50ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_r1 split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db214415b814e6d8c5309e1b993d9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_r2 split:   0%|          | 0/45460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d2331c1fdf453fb4dccc7b9c02d0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev_r2 split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4b8b5b1fec40f08b876016a0206952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_r2 split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b4bf1f19604250835ab6d143757799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_r3 split:   0%|          | 0/100459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677c3fc873024eb99d6600741b4e7dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev_r3 split:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e5863b825a4671a4dd852c16ca3537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_r3 split:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7e11885a9f44f9b9171b4b8cf39d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428717f1c0344c63a5cf6e79c133e62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef5170e32ff44ff9b197be233b19693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86827fb31f141e3b9534582ac0f354c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/45460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3569847b8d4b1eafd9091b60c4dff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c68081e72d4616af63cb9b737f7726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6ebafbcd4349a2a9917182e14f7ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8872fc002d234421aa06b3cd3b555bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077a61953a864fbda06e79035c9589c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"facebook/anli\")\n",
    "dataset = dataset.filter(lambda x: x['reason'] != None and x['reason'] != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e59927ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train_r1: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 2923\n",
       "    })\n",
       "    dev_r1: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test_r1: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    train_r2: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 4861\n",
       "    })\n",
       "    dev_r2: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test_r2: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    train_r3: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 13375\n",
       "    })\n",
       "    dev_r3: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "    test_r3: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8262068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the ANLI dataset\n",
    "from tqdm import tqdm\n",
    "def evaluate_on_dataset(dataset):\n",
    "    results = []\n",
    "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    for example in tqdm(dataset):\n",
    "        premise = example['premise']\n",
    "        hypothesis = example['hypothesis']\n",
    "        prediction = evaluate(premise, hypothesis)\n",
    "        results.append({\n",
    "            'premise': premise,\n",
    "            'hypothesis': hypothesis,\n",
    "            'prediction': prediction,\n",
    "            'pred_label': get_prediction(prediction),\n",
    "            'gold_label': label_names[example['label']],\n",
    "            'reason': example['reason']\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f858feae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [05:11<00:00,  3.85it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_test_r3 = evaluate_on_dataset(dataset['test_r3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8efb717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'premise': \"It is Sunday today, let's take a look at the most popular posts of the last couple of days. Most of the articles this week deal with the iPhone, its future version called the iPhone 8 or iPhone Edition, and new builds of iOS and macOS. There are also some posts that deal with the iPhone rival called the Galaxy S8 and some other interesting stories. The list of the most interesting articles is available below. Stay tuned for more rumors and don't forget to follow us on Twitter.\",\n",
       "  'hypothesis': 'The day of the passage is usually when Christians praise the lord together',\n",
       "  'prediction': {'entailment': 2.4, 'neutral': 97.4, 'contradiction': 0.2},\n",
       "  'pred_label': 'neutral',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': \"Sunday is considered Lord's Day\"},\n",
       " {'premise': 'By The Associated Press WELLINGTON, New Zealand (AP) — All passengers and crew have survived a crash-landing of a plane in a lagoon in the Federated States of Micronesia. WELLINGTON, New Zealand (AP) — All passengers and crew have survived a crash-landing of a plane in a lagoon in the Federated States of Micronesia. Copyright © 2018 The Associated Press. All rights reserved. This material may not be published, broadcast, written or redistributed.',\n",
       "  'hypothesis': 'No children were killed in the accident.',\n",
       "  'prediction': {'entailment': 0.1, 'neutral': 99.9, 'contradiction': 0.0},\n",
       "  'pred_label': 'neutral',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': 'The context confirms that everybody survived the accident, so there is no way that a child was killed.'},\n",
       " {'premise': 'Tokyo - Food group Nestle is seeking to lure Japanese holiday shoppers with a taste for fine snacking with a gold-wrapped Kit Kat chocolate bar. The single finger Kit Kat is wrapped in a thin layer of gold leaf. Only 500 of the bars go on sale from Dec. 29 with a price tag of around 2,016 yen ($16). The Kit Kat chocolate bar made its debut in Japan in 1973 and since then a variety of flavors -- from green tea to wasabi -- have been produced.',\n",
       "  'hypothesis': 'Japanese like kit kat. ',\n",
       "  'prediction': {'entailment': 84.0, 'neutral': 15.9, 'contradiction': 0.1},\n",
       "  'pred_label': 'entailment',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': 'according to the text, The Kit Kat chocolate bar made its debut in Japan in 1973 and since then a variety of flavors -- from green tea to wasabi -- have been produced, which means if  they have been so many produced it is because they like it. '},\n",
       " {'premise': 'Governor Greg Abbott has called for a statewide show of support for law enforcement Friday, July 7. Locally, a 15-minute program is planned at 9 a.m. at Memorial Lane Park, 550 N. Travis St. The governor is asking law enforcement officers to turn on red and blue flashing lights for one-minute at 10 a.m. Multiple law enforcement officers were shot and killed in Dallas one year ago.',\n",
       "  'hypothesis': 'Law enforcement officers and the people at the Travis St. memorial do not show their support at the same time.',\n",
       "  'prediction': {'entailment': 11.9, 'neutral': 75.8, 'contradiction': 12.3},\n",
       "  'pred_label': 'contradiction',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': 'The Travis St.memorial program begins at 9 a.m. Law enforcement officers were asked to turn on red and blue flashing lights for one-minute at 10 a.m.'},\n",
       " {'premise': 'Sept 4 (Reuters) - J.P. Morgan Asset Management, a unit of JPMorgan Chase & Co, said it appointed Pietro Grassano the new country head for France. Based in Paris, Grassano started in his new role on Sept. 1, J.P. Morgan Asset Management said in a statement. Grassano, who has been with the company since 2002, was previously the head of sales for Italy, covering wholesale and retail distribution. He has earlier worked at BNP Paribas Asset Management.',\n",
       "  'hypothesis': 'Pietro Grassano was once the country head for France.',\n",
       "  'prediction': {'entailment': 2.9, 'neutral': 55.1, 'contradiction': 42.0},\n",
       "  'pred_label': 'contradiction',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': '\"J.P. Morgan Asset Management, a unit of JPMorgan Chase & Co, said it appointed Pietro Grassano the new country head for France.\" I think it was difficult because I worded it past tense, \"He was ONCE the country head\", but I believe that statement is true because it is past Sept 1 when he was appointed.'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_r3[:5]  # Display the first 5 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e1258",
   "metadata": {},
   "source": [
    "## Evaluate Metrics\n",
    "\n",
    "Let's use the huggingface `evaluate` package to compute the performance of the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e2e9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "accuracy = load(\"accuracy\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "f1 = load(\"f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ab24e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d04f0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6666666666666666,\n",
       " 'f1': 0.6666666666666666,\n",
       " 'precision': 1.0,\n",
       " 'recall': 0.5}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_metrics.compute(predictions=[0, 1, 0], references=[0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909d58b",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "Compute the classification metrics on the baseline model on each section of the ANLI dataset.\n",
    "\n",
    "https://www.kaggle.com/code/faijanahamadkhan/llm-evaluation-framework-hugging-face provides good documentation on how to use the Huggingface evaluate library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51fbc81",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
