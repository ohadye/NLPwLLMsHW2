{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c468709d",
   "metadata": {},
   "source": [
    "# ImpPres with LLM\n",
    "\n",
    "You have to implement in this notebook a better ImpPres classifier using an LLM.\n",
    "This classifier must be implemented using DSPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cec0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the DSPy environment with the language model - for grok the parameters must be:\n",
    "# env variable should be in os.environ['XAI_API_KEY']\n",
    "# \"xai/grok-3-mini\"\n",
    "import os\n",
    "import dspy\n",
    "\n",
    "with open(\"grok_key.ini\") as f:\n",
    "        for line in f:\n",
    "            if \"XAI_API_KEY\" in line and not line.strip().startswith(\"#\"):\n",
    "                key_value = line.strip().split(\"=\")\n",
    "                if len(key_value) == 2:\n",
    "                    os.environ[\"XAI_API_KEY\"] = key_value[1].split()[0]\n",
    "\n",
    "with open(\"gemini_key.ini\") as f:\n",
    "        for line in f:\n",
    "            if \"GEMINI_API_KEY\" in line and not line.strip().startswith(\"#\"):\n",
    "                key_value = line.strip().split(\"=\")\n",
    "                if len(key_value) == 2:\n",
    "                    os.environ[\"GEMINI_API_KEY\"] = key_value[1].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f041bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lm = dspy.LM('xai/grok-3-mini', api_key=os.environ['XAI_API_KEY'])\n",
    "# for ollama \n",
    "# lm = dspy.LM('ollama_chat/devstral', api_base='http://localhost:11434', api_key='')\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b60da44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "## Implement the DSPy classifier program.\n",
    "\n",
    "#Basic label signature\n",
    "class anli_classification_signature(dspy.Signature):\n",
    "\n",
    "    \"\"\"Label the relationship between given premise and hypothesis.\"\"\"\n",
    "    \n",
    "    premise: str = dspy.InputField()\n",
    "    hypothesis: str = dspy.InputField()\n",
    "\n",
    "    label: Literal['entailment', 'contradiction', 'neutral'] = dspy.OutputField()\n",
    "\n",
    "#Paradigm signature\n",
    "class paradigm_signature(dspy.Signature):\n",
    "\n",
    "    \"\"\"Label the relationship between 19 transformations of a ( premise , hypothesis ) pair.\"\"\"\n",
    "\n",
    "    premises: list[str] = dspy.InputField()\n",
    "    hypotheses: list[str] = dspy.InputField()\n",
    "    output_labels: list[Literal['entailment', 'contradiction', 'neutral']] = dspy.OutputField()\n",
    "\n",
    "#Using CoT\n",
    "label_prompt = dspy.ChainOfThought(anli_classification_signature)\n",
    "\n",
    "#Creating a modul to predict a complete paradigm\n",
    "class paradigm_module(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.signature = paradigm_signature\n",
    "        #using a single prompt per pair\n",
    "        self.label_prompt = label_prompt\n",
    "\n",
    "    #packaging all predictions into a list    \n",
    "    def forward(self, premises, hypotheses, **kwargs) -> dspy.Prediction:\n",
    "        \n",
    "        output_labels = []\n",
    "\n",
    "        for p, h in zip(premises, hypotheses):\n",
    "            result = self.label_prompt(premise=p, hypothesis=h)  # joint_prompt is a DSPy module\n",
    "            output_labels.append(result.label)\n",
    "        \n",
    "        return dspy.Prediction({\"output_labels\": output_labels})\n",
    "\n",
    "label_map = {\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"contradiction\": 2\n",
    "}\n",
    "\n",
    "#reward based on paradigm accuracy\n",
    "def paradigm_reward(data, pred: dspy.Prediction):\n",
    "    #print(f\"type(pred.labels): {type(pred.labels)}\")\n",
    "    print(f\"pred.labels: {pred.output_labels}\")\n",
    "    golds = data[\"gold_labels\"]\n",
    "    preds = [label_map[item] for item in pred.output_labels]\n",
    "    acc = sum(p == g for p, g in zip(preds, golds)) / len(golds)\n",
    "    return acc\n",
    "\n",
    "paradigm_refine = dspy.Refine(\n",
    "    module=paradigm_module(), \n",
    "    N=3, reward_fn=paradigm_reward, \n",
    "    threshold=0.7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab422d",
   "metadata": {},
   "source": [
    "## Load ImpPres Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0438789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for section: presupposition_all_n_presupposition\n",
      "Loading dataset for section: presupposition_both_presupposition\n",
      "Loading dataset for section: presupposition_change_of_state\n",
      "Loading dataset for section: presupposition_cleft_existence\n",
      "Loading dataset for section: presupposition_cleft_uniqueness\n",
      "Loading dataset for section: presupposition_only_presupposition\n",
      "Loading dataset for section: presupposition_possessed_definites_existence\n",
      "Loading dataset for section: presupposition_possessed_definites_uniqueness\n",
      "Loading dataset for section: presupposition_question_presupposition\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sections = ['presupposition_all_n_presupposition', \n",
    "            'presupposition_both_presupposition', \n",
    "            'presupposition_change_of_state', \n",
    "            'presupposition_cleft_existence', \n",
    "            'presupposition_cleft_uniqueness', \n",
    "            'presupposition_only_presupposition', \n",
    "            'presupposition_possessed_definites_existence', \n",
    "            'presupposition_possessed_definites_uniqueness', \n",
    "            'presupposition_question_presupposition']\n",
    "\n",
    "dataset = {}\n",
    "for section in sections:\n",
    "    print(f\"Loading dataset for section: {section}\")\n",
    "    dataset[section] = load_dataset(\"facebook/imppres\", section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e1258",
   "metadata": {},
   "source": [
    "## Evaluate Metrics\n",
    "\n",
    "Let's use the huggingface `evaluate` package to compute the performance of the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2e9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "accuracy = load(\"accuracy\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "f1 = load(\"f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ab24e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909d58b",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "Compute the classification metrics on the baseline LLM model on each test section of the ANLI dataset for samples that have a non-empty 'reason' field.\n",
    "\n",
    "You also must show a comparison between the DeBERTa baseline model and this LLM baseline model. The comparison metric should compute the agreement between the two models:\n",
    "* On how many samples they are both correct [Correct]\n",
    "* On how many samples Model1 is correct and Model2 is incorrect [Correct1]\n",
    "* On how many samples Model1 is incorrect and Model2 is correct [Correct2]\n",
    "* On how many samples both are incorrect [Incorrect]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51fbc81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "abb01658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'premise': 'The guest had found John.',\n",
       "  'hypothesis': 'John used to be in an unknown location.',\n",
       "  'trigger': 'unembedded',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'positive',\n",
       "  'gold_label': 0,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '0e',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'The guest had found John.',\n",
       "  'hypothesis': \"John didn't used to be in an unknown location.\",\n",
       "  'trigger': 'unembedded',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'negated',\n",
       "  'gold_label': 2,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '1c',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'The guest had found John.',\n",
       "  'hypothesis': 'Peter used to be in an unknown location.',\n",
       "  'trigger': 'unembedded',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'neutral',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '2n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"The guest hadn't found John.\",\n",
       "  'hypothesis': 'John used to be in an unknown location.',\n",
       "  'trigger': 'negated',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'positive',\n",
       "  'gold_label': 0,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '3e',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"The guest hadn't found John.\",\n",
       "  'hypothesis': \"John didn't used to be in an unknown location.\",\n",
       "  'trigger': 'negated',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'negated',\n",
       "  'gold_label': 2,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '4c',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"The guest hadn't found John.\",\n",
       "  'hypothesis': 'Peter used to be in an unknown location.',\n",
       "  'trigger': 'negated',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'neutral',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '5n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'Had the guest found John?',\n",
       "  'hypothesis': 'John used to be in an unknown location.',\n",
       "  'trigger': 'interrogative',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'positive',\n",
       "  'gold_label': 0,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '6e',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'Had the guest found John?',\n",
       "  'hypothesis': \"John didn't used to be in an unknown location.\",\n",
       "  'trigger': 'interrogative',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'negated',\n",
       "  'gold_label': 2,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '7c',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'Had the guest found John?',\n",
       "  'hypothesis': 'Peter used to be in an unknown location.',\n",
       "  'trigger': 'interrogative',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'neutral',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '8n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'The guest might have found John.',\n",
       "  'hypothesis': 'John used to be in an unknown location.',\n",
       "  'trigger': 'modal',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'positive',\n",
       "  'gold_label': 0,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '9e',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'The guest might have found John.',\n",
       "  'hypothesis': \"John didn't used to be in an unknown location.\",\n",
       "  'trigger': 'modal',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'negated',\n",
       "  'gold_label': 2,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '10c',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'The guest might have found John.',\n",
       "  'hypothesis': 'Peter used to be in an unknown location.',\n",
       "  'trigger': 'modal',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'neutral',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '11n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"If the guest had found John, it's okay.\",\n",
       "  'hypothesis': 'John used to be in an unknown location.',\n",
       "  'trigger': 'conditional',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'positive',\n",
       "  'gold_label': 0,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '12e',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"If the guest had found John, it's okay.\",\n",
       "  'hypothesis': \"John didn't used to be in an unknown location.\",\n",
       "  'trigger': 'conditional',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'negated',\n",
       "  'gold_label': 2,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '13c',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"If the guest had found John, it's okay.\",\n",
       "  'hypothesis': 'Peter used to be in an unknown location.',\n",
       "  'trigger': 'conditional',\n",
       "  'trigger1': 'Not_In_Example',\n",
       "  'trigger2': 'Not_In_Example',\n",
       "  'presupposition': 'neutral',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '14n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"The guest hadn't found John.\",\n",
       "  'hypothesis': 'The guest had found John.',\n",
       "  'trigger': 'Not_In_Example',\n",
       "  'trigger1': 'negated',\n",
       "  'trigger2': 'unembedded',\n",
       "  'presupposition': 'Not_In_Example',\n",
       "  'gold_label': 2,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '15c',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'Had the guest found John?',\n",
       "  'hypothesis': 'The guest had found John.',\n",
       "  'trigger': 'Not_In_Example',\n",
       "  'trigger1': 'interrogative',\n",
       "  'trigger2': 'unembedded',\n",
       "  'presupposition': 'Not_In_Example',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '16n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': 'The guest might have found John.',\n",
       "  'hypothesis': 'The guest had found John.',\n",
       "  'trigger': 'Not_In_Example',\n",
       "  'trigger1': 'modal',\n",
       "  'trigger2': 'unembedded',\n",
       "  'presupposition': 'Not_In_Example',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '17n',\n",
       "  'paradigmID': 0},\n",
       " {'premise': \"If the guest had found John, it's okay.\",\n",
       "  'hypothesis': 'The guest had found John.',\n",
       "  'trigger': 'Not_In_Example',\n",
       "  'trigger1': 'conditional',\n",
       "  'trigger2': 'unembedded',\n",
       "  'presupposition': 'Not_In_Example',\n",
       "  'gold_label': 1,\n",
       "  'UID': 'change_of_state',\n",
       "  'pairID': '18n',\n",
       "  'paradigmID': 0}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset[\"presupposition_change_of_state\"][\"change_of_state\"])[:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4da07339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred.labels: ['neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'entailment', 'neutral', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "premises = [entry['premise'] for entry in list(dataset[\"presupposition_change_of_state\"][\"change_of_state\"])[:19]]\n",
    "hypotheses = [entry['hypothesis'] for entry in list(dataset[\"presupposition_change_of_state\"][\"change_of_state\"])[:19]]\n",
    "gold_labels = [entry['gold_label'] for entry in list(dataset[\"presupposition_change_of_state\"][\"change_of_state\"])[:19]]\n",
    "prediction = paradigm_refine(**{\"premises\": premises, \"hypotheses\": hypotheses, \"gold_labels\": gold_labels })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "424a74d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9561403508771931}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = [label_map[item] for item in prediction.output_labels]\n",
    "references = [item for item in gold_labels]\n",
    "\n",
    "\n",
    "print(precision.compute(predictions= predictions, references= references, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "25642b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"imppres_dataset.json\", \"r\") as f:\n",
    "    merged_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "543debb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing section: presupposition_all_n_presupposition\n",
      "Processing paradigm: 0\n",
      "pred.labels: ['neutral', 'neutral', 'contradiction', 'entailment', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'entailment', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing paradigm: 1\n",
      "pred.labels: ['contradiction', 'neutral', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'entailment', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.9532163742690059}\n",
      "Processing paradigm: 2\n",
      "pred.labels: ['entailment', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'entailment', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'entailment', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.9532163742690059}\n",
      "Processing paradigm: 3\n",
      "pred.labels: ['entailment', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'contradiction', 'entailment', 'entailment', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.8596491228070174}\n",
      "Processing paradigm: 4\n",
      "pred.labels: ['contradiction', 'entailment', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'contradiction', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.9157894736842105}\n",
      "Processing paradigm: 5\n",
      "pred.labels: ['neutral', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'entailment', 'entailment', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment']\n",
      "Paradigm results:\n",
      "{'precision': 0.9532163742690059}\n",
      "Processing paradigm: 6\n",
      "pred.labels: ['entailment', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'contradiction', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'entailment', 'contradiction', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing section: presupposition_both_presupposition\n",
      "Processing paradigm: 0\n",
      "pred.labels: ['contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'entailment', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'neutral', 'neutral', 'neutral', 'entailment']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing paradigm: 1\n",
      "pred.labels: ['entailment', 'entailment', 'neutral', 'neutral', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.9532163742690059}\n",
      "Processing paradigm: 2\n",
      "pred.labels: ['neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'entailment', 'neutral', 'contradiction', 'entailment', 'contradiction', 'neutral', 'neutral', 'entailment', 'contradiction', 'entailment', 'neutral', 'contradiction', 'neutral', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing paradigm: 3\n",
      "pred.labels: ['neutral', 'entailment', 'entailment', 'neutral', 'neutral', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'entailment', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.9532163742690059}\n",
      "Processing paradigm: 4\n",
      "pred.labels: ['contradiction', 'entailment', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'neutral', 'entailment', 'contradiction', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing paradigm: 5\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'entailment', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 0.9532163742690059}\n",
      "Processing paradigm: 6\n",
      "pred.labels: ['contradiction', 'entailment', 'neutral', 'neutral', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing section: presupposition_change_of_state\n",
      "Processing paradigm: 0\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral']\n",
      "pred.labels: ['entailment', 'neutral', 'contradiction', 'neutral', 'contradiction', 'entailment', 'entailment', 'neutral', 'neutral', 'entailment', 'contradiction', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.9035087719298246}\n",
      "Processing paradigm: 1\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 0.7591706539074959}\n",
      "Processing paradigm: 2\n",
      "pred.labels: ['entailment', 'entailment', 'contradiction', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'contradiction', 'contradiction', 'neutral', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.863157894736842}\n",
      "Processing paradigm: 3\n",
      "pred.labels: ['contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral']\n",
      "pred.labels: ['contradiction', 'entailment', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.6842105263157895}\n",
      "Processing paradigm: 4\n",
      "pred.labels: ['entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'neutral', 'entailment', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'entailment', 'neutral', 'neutral', 'entailment']\n",
      "Paradigm results:\n",
      "{'precision': 0.8851674641148326}\n",
      "Processing paradigm: 5\n",
      "pred.labels: ['entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral']\n",
      "pred.labels: ['entailment', 'neutral', 'neutral', 'neutral', 'contradiction', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral']\n",
      "pred.labels: ['entailment', 'contradiction', 'neutral', 'entailment', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 0.5956937799043063}\n",
      "Processing paradigm: 6\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'contradiction', 'neutral']\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'contradiction', 'contradiction']\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'contradiction', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 0.5139318885448917}\n",
      "Processing section: presupposition_cleft_existence\n",
      "Processing paradigm: 0\n",
      "pred.labels: ['contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'contradiction', 'contradiction', 'neutral', 'entailment', 'neutral', 'entailment', 'neutral', 'contradiction', 'entailment', 'neutral', 'entailment', 'entailment', 'entailment', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment']\n",
      "pred.labels: ['contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.8195488721804511}\n",
      "Processing paradigm: 1\n",
      "pred.labels: ['contradiction', 'neutral', 'neutral', 'entailment', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction']\n",
      "pred.labels: ['contradiction', 'contradiction', 'neutral', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'neutral', 'contradiction', 'entailment', 'neutral', 'neutral', 'entailment', 'neutral', 'entailment', 'entailment', 'contradiction', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 0.9013157894736842}\n",
      "Processing paradigm: 2\n",
      "pred.labels: ['neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.8596491228070174}\n",
      "Processing paradigm: 3\n",
      "pred.labels: ['contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['contradiction', 'neutral', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.8406432748538011}\n",
      "Processing paradigm: 4\n",
      "pred.labels: ['neutral', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.8380566801619433}\n",
      "Processing paradigm: 5\n",
      "pred.labels: ['neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.8596491228070174}\n",
      "Processing paradigm: 6\n",
      "pred.labels: ['entailment', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.8380566801619433}\n",
      "Processing section: presupposition_cleft_uniqueness\n",
      "Processing paradigm: 0\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral']\n",
      "pred.labels: ['contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral']\n",
      "pred.labels: ['contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.4101161995898838}\n",
      "Processing paradigm: 1\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'entailment', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'entailment', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.5029239766081871}\n",
      "Processing paradigm: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ohad/LLMHW2/nlp-with-llms-2025-hw2-main/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'neutral', 'contradiction', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'neutral', 'contradiction', 'entailment', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.8035087719298245}\n",
      "Processing paradigm: 3\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral']\n",
      "pred.labels: ['entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.5029239766081871}\n",
      "Processing paradigm: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ohad/LLMHW2/nlp-with-llms-2025-hw2-main/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'contradiction', 'neutral', 'contradiction']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/11 15:13:32 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=4000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred.labels: ['neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.5029239766081871}\n",
      "Processing paradigm: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ohad/LLMHW2/nlp-with-llms-2025-hw2-main/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral']\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.7894736842105263}\n",
      "Processing paradigm: 6\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'entailment', 'entailment', 'neutral']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/11 15:26:16 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=4000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred.labels: ['neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'entailment', 'entailment', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.7587719298245614}\n",
      "Processing section: presupposition_only_presupposition\n",
      "Processing paradigm: 0\n",
      "pred.labels: ['neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.8380566801619433}\n",
      "Processing paradigm: 1\n",
      "pred.labels: ['contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'entailment', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.7942583732057416}\n",
      "Processing paradigm: 2\n",
      "pred.labels: ['contradiction', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/11 15:36:53 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=4000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred.labels: ['contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.7033492822966507}\n",
      "Processing paradigm: 3\n",
      "pred.labels: ['contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.8380566801619433}\n",
      "Processing paradigm: 4\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'entailment', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'entailment', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.7591706539074959}\n",
      "Processing paradigm: 5\n",
      "pred.labels: ['contradiction', 'neutral', 'entailment', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral']\n",
      "pred.labels: ['contradiction', 'entailment', 'entailment', 'contradiction', 'contradiction', 'neutral', 'entailment', 'entailment', 'neutral', 'neutral', 'contradiction', 'entailment', 'entailment', 'neutral', 'entailment', 'neutral', 'contradiction', 'entailment', 'contradiction']\n",
      "pred.labels: ['neutral', 'entailment', 'entailment', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'entailment', 'neutral', 'entailment', 'neutral', 'contradiction', 'entailment', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 0.7844611528822055}\n",
      "Processing paradigm: 6\n",
      "pred.labels: ['contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'contradiction']\n",
      "pred.labels: ['neutral', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'entailment', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'entailment', 'entailment', 'contradiction']\n",
      "pred.labels: ['neutral', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'entailment', 'neutral', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'entailment', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 0.8195488721804511}\n",
      "Processing section: presupposition_possessed_definites_existence\n",
      "Processing paradigm: 0\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'entailment', 'neutral', 'neutral', 'entailment', 'entailment']\n",
      "Paradigm results:\n",
      "{'precision': 0.8851674641148326}\n",
      "Processing paradigm: 1\n",
      "pred.labels: ['neutral', 'neutral', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'entailment', 'neutral', 'entailment', 'contradiction', 'contradiction', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing paradigm: 2\n",
      "pred.labels: ['neutral', 'entailment', 'entailment', 'contradiction', 'contradiction', 'neutral', 'neutral', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'neutral', 'entailment', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing paradigm: 3\n",
      "pred.labels: ['contradiction', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'contradiction', 'contradiction', 'entailment', 'neutral', 'entailment']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing paradigm: 4\n",
      "pred.labels: ['contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'neutral', 'neutral', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'neutral', 'entailment', 'entailment']\n",
      "Paradigm results:\n",
      "{'precision': 0.868421052631579}\n",
      "Processing paradigm: 5\n",
      "pred.labels: ['neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'entailment', 'contradiction', 'entailment', 'neutral', 'contradiction', 'entailment', 'neutral', 'entailment', 'contradiction', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing paradigm: 6\n",
      "pred.labels: ['entailment', 'contradiction', 'entailment', 'neutral', 'entailment', 'entailment', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing section: presupposition_possessed_definites_uniqueness\n",
      "Processing paradigm: 0\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'entailment', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing paradigm: 1\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction']\n",
      "pred.labels: ['neutral', 'entailment', 'contradiction', 'contradiction', 'entailment', 'neutral', 'entailment', 'neutral', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction']\n",
      "pred.labels: ['contradiction', 'entailment', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'neutral', 'entailment', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 0.5827067669172932}\n",
      "Processing paradigm: 2\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'entailment', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'contradiction', 'entailment', 'entailment', 'neutral', 'contradiction', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 0.6}\n",
      "Processing paradigm: 3\n",
      "pred.labels: ['neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'entailment', 'neutral', 'contradiction', 'neutral', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.6175438596491228}\n",
      "Processing paradigm: 4\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 0.863157894736842}\n",
      "Processing paradigm: 5\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'contradiction', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'contradiction', 'entailment', 'neutral', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'contradiction', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'contradiction', 'entailment', 'entailment', 'contradiction', 'neutral', 'entailment', 'neutral', 'contradiction', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.5029239766081871}\n",
      "Processing paradigm: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ohad/LLMHW2/nlp-with-llms-2025-hw2-main/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred.labels: ['neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "pred.labels: ['entailment', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'entailment', 'entailment', 'neutral', 'entailment', 'neutral', 'entailment', 'contradiction', 'entailment', 'entailment', 'neutral']\n",
      "pred.labels: ['neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.7141812865497076}\n",
      "Processing section: presupposition_question_presupposition\n",
      "Processing paradigm: 0\n",
      "pred.labels: ['contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'entailment', 'neutral', 'entailment']\n",
      "Paradigm results:\n",
      "{'precision': 0.8596491228070174}\n",
      "Processing paradigm: 1\n",
      "pred.labels: ['neutral', 'entailment', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'entailment', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'entailment', 'entailment', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.9157894736842105}\n",
      "Processing paradigm: 2\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'contradiction', 'contradiction', 'entailment', 'neutral', 'neutral', 'entailment', 'contradiction', 'entailment', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.9157894736842105}\n",
      "Processing paradigm: 3\n",
      "pred.labels: ['neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'neutral', 'contradiction', 'entailment', 'neutral', 'neutral', 'contradiction', 'neutral']\n",
      "Paradigm results:\n",
      "{'precision': 0.9157894736842105}\n",
      "Processing paradigm: 4\n",
      "pred.labels: ['neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'entailment', 'entailment', 'neutral', 'neutral', 'entailment', 'contradiction', 'contradiction', 'neutral', 'neutral', 'contradiction', 'contradiction', 'neutral', 'entailment', 'contradiction']\n",
      "Paradigm results:\n",
      "{'precision': 0.8045112781954886}\n",
      "Processing paradigm: 5\n",
      "pred.labels: ['contradiction', 'contradiction', 'neutral', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'entailment', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'entailment', 'neutral', 'entailment']\n",
      "Paradigm results:\n",
      "{'precision': 1.0}\n",
      "Processing paradigm: 6\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral']\n",
      "pred.labels: ['neutral', 'neutral', 'neutral', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'entailment', 'entailment', 'neutral', 'contradiction', 'neutral', 'entailment', 'entailment', 'neutral', 'entailment']\n",
      "Paradigm results:\n",
      "{'precision': 0.9561403508771931}\n",
      "Total results collected: 1197\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Assuming merged_dataset is a list or iterable of all entries from all sections,\n",
    "# each entry has a 'section' key and a 'paradigmID' key.\n",
    "\n",
    "all_results = []\n",
    "\n",
    "section_groups = defaultdict(list)\n",
    "for entry in merged_dataset:\n",
    "    section_groups[entry[\"section\"]].append(entry)\n",
    "\n",
    "for section, entries_in_section in section_groups.items():\n",
    "    print(f\"Processing section: {section}\")\n",
    "\n",
    "    paradigm_groups = defaultdict(list)\n",
    "    for entry in entries_in_section:\n",
    "        paradigm_groups[entry[\"paradigmID\"]].append(entry)\n",
    "\n",
    "    # Select the first 7 paradigms sorted by paradigmID\n",
    "    selected_paradigm_ids = sorted(paradigm_groups.keys())[:7]\n",
    "\n",
    "    for paradigm_id in selected_paradigm_ids:\n",
    "        print(f\"Processing paradigm: {paradigm_id}\")\n",
    "        paradigm_entries = paradigm_groups[paradigm_id]\n",
    "        random.shuffle(paradigm_entries)\n",
    "\n",
    "        premises = [e[\"premise\"] for e in paradigm_entries]\n",
    "        hypotheses = [e[\"hypothesis\"] for e in paradigm_entries]\n",
    "        gold_labels = [e[\"gold_label\"] for e in paradigm_entries]\n",
    "\n",
    "        input_batch = {\n",
    "            \"premises\": premises,\n",
    "            \"hypotheses\": hypotheses,\n",
    "            \"gold_labels\": gold_labels\n",
    "        }\n",
    "\n",
    "        prediction = paradigm_refine(**input_batch)\n",
    "\n",
    "        predicted_labels = prediction.output_labels\n",
    "\n",
    "        for e, pred_label in zip(paradigm_entries, predicted_labels):\n",
    "            result_entry = dict(e)\n",
    "            result_entry[\"pred_label\"] = pred_label\n",
    "            all_results.append(result_entry)\n",
    "        \n",
    "        print(f\"Paradigm results:\")\n",
    "\n",
    "        predictions = [label_map[item] for item in predicted_labels]\n",
    "        references = [item[\"gold_label\"] for item in paradigm_entries]\n",
    "\n",
    "        print(precision.compute(predictions= predictions, references= references, average=\"weighted\"))\n",
    "        \n",
    "\n",
    "print(f\"Total results collected: {len(all_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fe155f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [trigger, trigger2, presupposition, accuracy, n_examples]\n",
      "Index: []\n",
      "overall accuracy:\n",
      "{'precision': 0.8232283709539563}\n",
      "=== Accuracy per Section ===\n",
      "                                         section  accuracy\n",
      "0            presupposition_all_n_presupposition  0.932331\n",
      "1             presupposition_both_presupposition  0.977444\n",
      "2                 presupposition_change_of_state  0.714286\n",
      "3                 presupposition_cleft_existence  0.774436\n",
      "4                presupposition_cleft_uniqueness  0.548872\n",
      "5             presupposition_only_presupposition  0.714286\n",
      "6   presupposition_possessed_definites_existence  0.939850\n",
      "7  presupposition_possessed_definites_uniqueness  0.661654\n",
      "8         presupposition_question_presupposition  0.887218\n",
      "           trigger        trigger1        trigger2  presupposition  accuracy  \\\n",
      "11         negated  Not_In_Example  Not_In_Example         neutral  0.968254   \n",
      "2      conditional  Not_In_Example  Not_In_Example         neutral  0.952381   \n",
      "8            modal  Not_In_Example  Not_In_Example         neutral  0.952381   \n",
      "5    interrogative  Not_In_Example  Not_In_Example         neutral  0.936508   \n",
      "0   Not_In_Example      unembedded      unembedded  Not_In_Example  0.924603   \n",
      "14      unembedded  Not_In_Example  Not_In_Example         neutral  0.920635   \n",
      "13      unembedded  Not_In_Example  Not_In_Example         negated  0.841270   \n",
      "15      unembedded  Not_In_Example  Not_In_Example        positive  0.825397   \n",
      "12         negated  Not_In_Example  Not_In_Example        positive  0.761905   \n",
      "7            modal  Not_In_Example  Not_In_Example         negated  0.730159   \n",
      "10         negated  Not_In_Example  Not_In_Example         negated  0.666667   \n",
      "1      conditional  Not_In_Example  Not_In_Example         negated  0.634921   \n",
      "4    interrogative  Not_In_Example  Not_In_Example         negated  0.619048   \n",
      "3      conditional  Not_In_Example  Not_In_Example        positive  0.555556   \n",
      "9            modal  Not_In_Example  Not_In_Example        positive  0.539683   \n",
      "6    interrogative  Not_In_Example  Not_In_Example        positive  0.492063   \n",
      "\n",
      "    n_examples  \n",
      "11          63  \n",
      "2           63  \n",
      "8           63  \n",
      "5           63  \n",
      "0          252  \n",
      "14          63  \n",
      "13          63  \n",
      "15          63  \n",
      "12          63  \n",
      "7           63  \n",
      "10          63  \n",
      "1           63  \n",
      "4           63  \n",
      "3           63  \n",
      "9           63  \n",
      "6           63  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert results to a DataFrame for easy grouping\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Map labels to integers\n",
    "label_map = {\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"contradiction\": 2\n",
    "}\n",
    "df[\"gold_int\"] = df[\"gold_label\"]\n",
    "df[\"pred_int\"] = df[\"pred_label\"].map(label_map)\n",
    "\n",
    "# ---- 1. Accuracy per section ----\n",
    "section_perf = (\n",
    "    df.groupby(\"section\")\n",
    "      .apply(lambda g: (g[\"gold_int\"] == g[\"pred_int\"]).mean(), include_groups=False)\n",
    "      .reset_index(name=\"accuracy\")\n",
    ")\n",
    "\n",
    "transform_perf = (\n",
    "    df.groupby([\"trigger\", \"trigger1\", \"trigger2\", \"presupposition\"])\n",
    "      .agg(\n",
    "          accuracy=(\"gold_int\", lambda x: (x == df.loc[x.index, \"pred_int\"]).mean()),\n",
    "          n_examples=(\"gold_int\", \"size\")\n",
    "      )\n",
    "      .reset_index()\n",
    "      .sort_values(\"accuracy\", ascending=False)\n",
    ")\n",
    "\n",
    "# Filter rows where trigger1 == 'negated'\n",
    "negated_df = df[df[\"trigger1\"] == \"negated\"]\n",
    "\n",
    "# Now group by the other columns, e.g., trigger, trigger2, presupposition\n",
    "negated_perf = (\n",
    "    negated_df.groupby([\"trigger\", \"trigger2\", \"presupposition\"])\n",
    "        .agg(\n",
    "            accuracy=(\"gold_int\", lambda x: (x == negated_df.loc[x.index, \"pred_int\"]).mean()),\n",
    "            n_examples=(\"gold_int\", \"size\")\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(\"accuracy\", ascending=False)\n",
    ")\n",
    "\n",
    "print(negated_perf)\n",
    "print(\"overall accuracy:\")\n",
    "print(precision.compute(predictions= df[\"pred_int\"], references= df[\"gold_int\"], average=\"weighted\", zero_division = 0))\n",
    "print(\"=== Accuracy per Section ===\")\n",
    "print(section_perf)\n",
    "print(transform_perf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03114450",
   "metadata": {},
   "source": [
    "It seems like I made a mistake in imppres.ipynb and entered trigger2 data into trigger1 key, which is why transformation 0 has 252 = 4 * 7 * 9 entries.\n",
    "\n",
    "I've fixed it now but to apply it here would mean circumventing the randomization somehow.\n",
    "\n",
    "I don't trust the method in which I've refined this prompt. \n",
    "\n",
    "The process simply tries the whole paradigm again with a different temperture if group average is low enough.\n",
    "\n",
    "I've had trouble finding a way to apply DSPy refinement to a single prompt based on the score of a group of 19."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
